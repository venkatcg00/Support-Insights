services:
  mysql:
    image: mysql:latest
    container_name: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: ${PROJECT_PASSWORD}
      MYSQL_DATABASE: ${DB_NAME}
      MYSQL_USER: ${PROJECT_USER}
      MYSQL_PASSWORD: ${PROJECT_PASSWORD}
    ports:
      - "${DB_PORT}:${DB_PORT}"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql-init:/docker-entrypoint-initdb.d
    networks:
      - data-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "${PROJECT_USER}", "-p${PROJECT_PASSWORD}"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s

  mongodb:
    image: mongo:latest
    container_name: mongodb
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${PROJECT_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${PROJECT_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_DB}
    ports:
      - "${MONGO_PORT}:${MONGO_PORT}"
    volumes:
      - mongo_data:/data/db
    networks:
      - data-network

  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    restart: always
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/bitnami/zookeeper
    networks:
      - data-network

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${KAFKA_BOOTSTRAP_SERVERS},PLAINTEXT_HOST://localhost:29092
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - data-network

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    restart: always
    depends_on:
      - kafka
    ports:
      - "1234:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    networks:
      - data-network

  minio:
    image: minio/minio
    container_name: minio
    restart: always
    ports:
      - "${MINIO_PORT}:${MINIO_PORT}"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${PROJECT_USER}
      MINIO_ROOT_PASSWORD: ${PROJECT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    networks:
      - data-network

  airflow:
    image: apache/airflow:latest
    container_name: airflow
    restart: always
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+pymysql://${PROJECT_USER}:${PROJECT_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}
      AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: 30
      AIRFLOW__CORE__DAG_SERIALIZATION: "True"
      AIRFLOW__CORE__STORE_SERIALIZED_DAGS: "True"
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      _AIRFLOW_WWW_USER_USERNAME: ${PROJECT_USER}
      _AIRFLOW_WWW_USER_PASSWORD: ${PROJECT_PASSWORD}
      _AIRFLOW_WWW_USER_FIRSTNAME: ${AIRFLOW_FIRSTNAME}
      _AIRFLOW_WWW_USER_LASTNAME: ${AIRFLOW_LASTNAME}
      _AIRFLOW_WWW_USER_EMAIL: ${AIRFLOW_EMAIL}
      _AIRFLOW_WWW_USER_ROLE: Admin
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_NAME: ${DB_NAME}
      DB_USER: ${PROJECT_USER}
      DB_PASSWORD: ${PROJECT_PASSWORD}
      MONGO_HOST: ${MONGO_HOST}
      MONGO_PORT: ${MONGO_PORT}
      MONGO_USER: ${PROJECT_USER}
      MONGO_PASSWORD: ${PROJECT_PASSWORD}
      MONGO_DB: ${MONGO_DB}
      MINIO_HOST: ${MINIO_HOST}
      MINIO_PORT: ${MINIO_PORT}
      MINIO_USER: ${PROJECT_USER}
      MINIO_PASSWORD: ${PROJECT_PASSWORD}
      MINIO_BUCKET: ${MINIO_BUCKET}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_TOPIC_NAME: ${KAFKA_TOPIC_NAME}
    volumes:
      - ./Data-Loaders/Batch-Processing:/opt/airflow/dags
      - ./Data-Loaders/plugins:/opt/airflow/plugins
      - airflow_logs:/opt/airflow/logs
    networks:
      - data-network
    depends_on:
      mysql:
        condition: service_healthy
    command: >
      bash -c "
      echo 'Initializing Airflow...' &&
      airflow db init &&
      pip install --no-cache-dir boto3 pandas kafka-python pymysql pymongo confluent-kafka pyspark --break-system-packages &&
      airflow users create -u ${PROJECT_USER} -p ${PROJECT_PASSWORD} -f ${AIRFLOW_FIRSTNAME} -l ${AIRFLOW_LASTNAME} -r Admin -e ${AIRFLOW_EMAIL} &&
      echo 'Airflow DB initialized and user created.' &&
      airflow webserver & airflow scheduler
      "

  python-runner:
    image: python:3.9-slim
    container_name: python-runner
    restart: always
    ports:
      - "1212:1212"
    environment:
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_NAME=${DB_NAME}
      - DB_USER=${PROJECT_USER}
      - DB_PASSWORD=${PROJECT_PASSWORD}
      - MONGO_HOST=${MONGO_HOST}
      - MONGO_PORT=${MONGO_PORT}
      - MONGO_USER=${PROJECT_USER}
      - MONGO_PASSWORD=${PROJECT_PASSWORD}
      - MONGO_DB=${MONGO_DB}
      - MINIO_HOST=${MINIO_HOST}
      - MINIO_PORT=${MINIO_PORT}
      - MINIO_USER=${PROJECT_USER}
      - MINIO_PASSWORD=${PROJECT_PASSWORD}
      - MINIO_BUCKET=${MINIO_BUCKET}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - KAFKA_TOPIC_NAME=${KAFKA_TOPIC_NAME}
    volumes:
      - ./Data-Generators:/app/scripts
      - python_runner_logs:/app/logs
    networks:
      - data-network
    depends_on:
      mysql:
        condition: service_healthy
    command: >
      bash -c "
      apt-get update && apt-get install -y netcat-openbsd && apt-get clean && rm -rf /var/lib/apt/lists/* &&
      pip install --no-cache-dir pandas sqlalchemy pymysql kafka-python pymongo boto3 confluent-kafka aiohttp --break-system-packages &&
      tail -f /dev/null
      "

networks:
  data-network:
    name: data-network

volumes:
  mysql_data:
  mongo_data:
  minio_data:
  kafka_data:
  zookeeper_data:
  airflow_logs:
  python_runner_logs: